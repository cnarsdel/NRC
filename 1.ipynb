{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433e321",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.12.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tcr_tda\n",
    "from tcr_tda import (\n",
    "    run_pipeline,\n",
    "    build_olga_pgen_human_TRB,\n",
    "    compute_distance_matrix,\n",
    "    compute_distance_matrices_parallel,\n",
    "    dm_to_graph,\n",
    "    dm_to_graph_parallel_threshold,\n",
    "    basic_network_metrics,\n",
    "    compute_persistence,\n",
    "    compute_persistence_batch,\n",
    "    plot_persistence_diagram,\n",
    "    plot_persistence_barcode,\n",
    "    plot_betti_curve,\n",
    "    node_removal_analysis,\n",
    "    node_removal_analysis_batch,\n",
    "    NodeRemovalResult,\n",
    ")\n",
    "\n",
    "AA_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"  # amino acid alphabet\n",
    "\n",
    "\n",
    "def random_cdr3(length: int) -> str:\n",
    "    return \"\".join(random.choice(AA_ALPHABET) for _ in range(length))\n",
    "\n",
    "\n",
    "def random_repertoire(n_seqs: int, min_len: int = 10, max_len: int = 14):\n",
    "    lengths = np.random.randint(min_len, max_len + 1, size=n_seqs)\n",
    "    return np.array([random_cdr3(int(L)) for L in lengths], dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100  # depth per dataset\n",
    "\n",
    "seqs_A = random_repertoire(N)\n",
    "seqs_B = random_repertoire(N)\n",
    "\n",
    "print(\"Dataset A (first 5):\", seqs_A[:5])\n",
    "print(\"Dataset B (first 5):\", seqs_B[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: test compute_distance_matrix\n",
    "\n",
    "dm_A = compute_distance_matrix(seqs_A)\n",
    "dm_B = compute_distance_matrix(seqs_B)\n",
    "\n",
    "print(\"Distance matrix A shape:\", dm_A.shape)\n",
    "print(\"Distance matrix B shape:\", dm_B.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: test compute_distance_matrices_parallel\n",
    "\n",
    "seqs_by_dataset = {\"A\": seqs_A, \"B\": seqs_B}\n",
    "dms_parallel = compute_distance_matrices_parallel(seqs_by_dataset)\n",
    "\n",
    "for name, dm in dms_parallel.items():\n",
    "    print(f\"{name}: shape {dm.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ee239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: test graph builders (sequential + parallel threshold) and basic_network_metrics\n",
    "\n",
    "# Use the dm_A computed above\n",
    "epsilon = 0.3  # toy threshold\n",
    "\n",
    "G_thresh = dm_to_graph(dm_A, nodes=seqs_A, mode=\"threshold\", epsilon=epsilon)\n",
    "metrics_thresh = basic_network_metrics(G_thresh)\n",
    "\n",
    "print(\"Sequential threshold graph metrics:\")\n",
    "for k, v in metrics_thresh.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "G_thresh_parallel = dm_to_graph_parallel_threshold(\n",
    "    dm_A,\n",
    "    nodes=seqs_A,\n",
    "    epsilon=epsilon,\n",
    "    include_weights=True,\n",
    "    max_workers=2,\n",
    ")\n",
    "\n",
    "metrics_thresh_parallel = basic_network_metrics(G_thresh_parallel)\n",
    "\n",
    "print(\"\\nParallel threshold graph metrics:\")\n",
    "for k, v in metrics_thresh_parallel.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: TDA on single matrix and batch\n",
    "\n",
    "hom_dim = 1\n",
    "\n",
    "diagram_A, betti_A = compute_persistence(dm_A, hom_dim=hom_dim)\n",
    "print(\"Diagram A shape:\", diagram_A.shape)\n",
    "print(\"Betti A length:\", len(betti_A))\n",
    "\n",
    "tda_batch = compute_persistence_batch({\"A\": dm_A, \"B\": dm_B}, hom_dim=hom_dim)\n",
    "\n",
    "for name, (dgm, bt) in tda_batch.items():\n",
    "    print(f\"{name}: diagram shape {dgm.shape}, betti length {len(bt)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7129d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: plot diagram, barcode, and Betti curve for dataset A\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plot_persistence_diagram(diagram_A, title=\"Random A – H1 diagram\")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plot_persistence_barcode(diagram_A, title=\"Random A – H1 barcode\")\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plot_betti_curve(betti_A, title=\"Random A – H1 Betti curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: NRA for a single sequence (node_removal_analysis)\n",
    "\n",
    "# Pick a sequence that definitely exists in seqs_A\n",
    "target_seq = seqs_A[0]\n",
    "print(\"Target sequence for NRA:\", target_seq)\n",
    "\n",
    "# Use G_thresh (graph on A) and dm_A\n",
    "nra_result = node_removal_analysis(\n",
    "    seq_to_remove=target_seq,\n",
    "    dm=dm_A,\n",
    "    node_labels=list(seqs_A),\n",
    "    hom_dim=hom_dim,\n",
    "    graph=G_thresh,\n",
    "    pgen_fn=None,  # no OLGA here to keep it light\n",
    ")\n",
    "\n",
    "print(\"\\nNRA result (single):\")\n",
    "print(\"  seq:\", nra_result.seq)\n",
    "print(\"  index:\", nra_result.index)\n",
    "print(\"  delta_betti_sum:\", nra_result.delta_betti_sum)\n",
    "print(\"  pgen:\", nra_result.pgen)\n",
    "print(\"  network metrics BEFORE:\", nra_result.network_metrics_before)\n",
    "print(\"  network metrics AFTER:\", nra_result.network_metrics_after)\n",
    "\n",
    "assert isinstance(nra_result, NodeRemovalResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: NRA for a few sequences in parallel (node_removal_analysis_batch)\n",
    "\n",
    "from tcr_tda.nra import node_removal_analysis_batch  # explicit import from subpackage\n",
    "\n",
    "seqs_to_remove = list(seqs_A[:5])  # first 5 sequences\n",
    "\n",
    "nra_results_batch = node_removal_analysis_batch(\n",
    "    seqs_to_remove=seqs_to_remove,\n",
    "    dm=dm_A,\n",
    "    node_labels=list(seqs_A),\n",
    "    hom_dim=hom_dim,\n",
    "    graph=G_thresh,\n",
    "    pgen_fn=None,\n",
    "    max_workers=2,\n",
    ")\n",
    "\n",
    "print(\"\\nNRA batch results (5 nodes):\")\n",
    "for seq, res in nra_results_batch.items():\n",
    "    print(f\"  {seq}: delta_betti_sum={res.delta_betti_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a55701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: test build_olga_pgen_human_TRB (optional, will skip if OLGA not installed)\n",
    "\n",
    "try:\n",
    "    pgen_fn = build_olga_pgen_human_TRB()\n",
    "    test_seq = seqs_A[1]\n",
    "    pgen_val = pgen_fn(test_seq)\n",
    "    print(\"OLGA Pgen test:\")\n",
    "    print(\"  sequence:\", test_seq)\n",
    "    print(\"  Pgen:\", pgen_val)\n",
    "except Exception as e:\n",
    "    print(\"OLGA not available or failed to initialize, skipping Pgen test.\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d380238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: end-to-end pipeline test on synthetic data (depth 100)\n",
    "\n",
    "BASE_DIR = Path(\"demo_random_data\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "OUT_DM = BASE_DIR / \"networks\"\n",
    "OUT_TDA = BASE_DIR / \"Topology\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Build two fake datasets, each with 100 sequences and a cdr3aa column\n",
    "df_A = pd.DataFrame({\"cdr3aa\": seqs_A})\n",
    "df_B = pd.DataFrame({\"cdr3aa\": seqs_B})\n",
    "\n",
    "df_A.to_csv(DATA_DIR / \"demo_A.txt\", sep=\"\\t\", index=False)\n",
    "df_B.to_csv(DATA_DIR / \"demo_B.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Wrote demo_A.txt and demo_B.txt to\", DATA_DIR.resolve())\n",
    "\n",
    "# Simple dataset filter (accept everything)\n",
    "def keep_all(name: str) -> bool:\n",
    "    return True\n",
    "\n",
    "# Run pipeline WITHOUT OLGA (pgen_builder=None)\n",
    "run_pipeline(\n",
    "    data_glob=str(DATA_DIR / \"*.txt\"),\n",
    "    out_dir_dm=str(OUT_DM),\n",
    "    out_dir_tda=str(OUT_TDA),\n",
    "    max_rows_per_dataset=None,  # use full depth 100\n",
    "    hom_dim=1,\n",
    "    cdr3_col=\"cdr3aa\",\n",
    "    dataset_name_filter=keep_all,\n",
    "    distance_metric=None,        # default: Needleman–Wunsch\n",
    "    build_graphs=True,\n",
    "    graph_mode=\"threshold\",\n",
    "    graph_epsilon=0.3,\n",
    "    parallel_graph_threshold=True,\n",
    "    pgen_builder=None,           # skip OLGA for demo\n",
    "    max_workers_dm=2,\n",
    "    max_workers_tda=2,\n",
    "    max_workers_node_removal=2,\n",
    ")\n",
    "\n",
    "print(\"\\nPipeline finished. Check outputs in:\")\n",
    "print(\"  Distance / graphs ->\", OUT_DM.resolve())\n",
    "print(\"  TDA ->\", OUT_TDA.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175083ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: quick inspection of saved outputs\n",
    "\n",
    "# Load combined NPZ\n",
    "dm_npz_path = OUT_DM / \"distance_matrices_and_nodes_all.npz\"\n",
    "npz = np.load(dm_npz_path, allow_pickle=True)\n",
    "\n",
    "print(\"Keys in NPZ:\", list(npz.keys())[:10])\n",
    "\n",
    "# Load one graph\n",
    "import networkx as nx\n",
    "\n",
    "graph_files = list(OUT_DM.glob(\"graph_*.gpickle\"))\n",
    "print(\"Graph files:\", [g.name for g in graph_files])\n",
    "\n",
    "if graph_files:\n",
    "    G_loaded = nx.read_gpickle(graph_files[0])\n",
    "    print(\"Loaded graph:\", graph_files[0].name)\n",
    "    print(\"  n_nodes:\", G_loaded.number_of_nodes())\n",
    "    print(\"  n_edges:\", G_loaded.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d0095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
